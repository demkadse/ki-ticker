<!doctype html>
<html lang="de">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>KI‑Ticker – Aktuelle KI‑News</title>
<meta name="description" content="Automatisierte Übersicht zu KI, Machine Learning, LLMs und Forschung.">
<link rel="stylesheet" href="style.css">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=pub-2616688648278798"></script>
</head>
<body>
<header class="header">
  <h1>KI‑Ticker</h1>
  <p class="tagline">Zuletzt aktualisiert: 16.02.2026 17:46 UTC</p>
</header>
<main>
<section class="grid">

        <article class="card">
          
          <h3><a href="https://aws.amazon.com/blogs/machine-learning/supercharge-regulated-workloads-with-claude-code-and-amazon-bedrock/" target="_blank">Supercharge regulated workloads with Claude Code and Amazon Bedrock</a></h3>
          <div class="meta">AWS ML Blog • aws.amazon.com • 16.02.2026 17:45 UTC</div>
          <p>The release of Anthropic Claude Sonnet 4.5 in the AWS GovCloud (US) Region introduces a straightforward on-ramp for AI-assisted development for workloads with regulatory compliance requirements. In this post, we explore how to combine Claude Sonnet 4.5 on Amazon Bedrock in AWS Go…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://www.theverge.com/podcast/879203/ring-search-party-super-bowl-ai-surveillance-privacy-security" target="_blank">Let&#8217;s talk about Ring, lost dogs, and the surveillance state</a></h3>
          <div class="meta">The Verge – AI • theverge.com • 16.02.2026 15:00 UTC</div>
          <p>Today, let’s talk about the camera company Ring, lost dogs, and the surveillance state.  You probably saw this ad during the Super Bowl a couple of weekends ago: Since it aired for a massive audience at the Super Bowl, Ring’s Search Party commercial has become a lightning rod for…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://www.theverge.com/ai-artificial-intelligence/879644/bytedance-seedance-safeguards-ai-video-copyright-infringement" target="_blank">After spooking Hollywood, ByteDance will tweak safeguards on new AI model</a></h3>
          <div class="meta">The Verge – AI • theverge.com • 16.02.2026 11:29 UTC</div>
          <p>TikTok creator ByteDance says that it is working to improve safeguards on its new AI video generator after Disney, Paramount, and Hollywood trade groups accused the tool of violating copyright protections. Concerns were raised after hyperrealistic videos generated by the Seedance…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12316" target="_blank">GT-HarmBench: Benchmarking AI Safety Risks Through the Lens of Game Theory</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12316v1 Announce Type: new 
Abstract: Frontier AI systems are increasingly capable and deployed in high-stakes multi-agent environments. However, existing AI safety benchmarks largely evaluate single agents, leaving multi-agent risks such as coordination failure and co…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12356" target="_blank">A Theoretical Framework for Adaptive Utility-Weighted Benchmarking</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12356v1 Announce Type: new 
Abstract: Benchmarking has long served as a foundational practice in machine learning and, increasingly, in modern AI systems such as large language models, where shared tasks, metrics, and leaderboards offer a common basis for measuring pro…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12389" target="_blank">Evolving Beyond Snapshots: Harmonizing Structure and Sequence via Entity State Tuning for Temporal Knowledge Graph Forecasting</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12389v1 Announce Type: new 
Abstract: Temporal knowledge graph (TKG) forecasting requires predicting future facts by jointly modeling structural dependencies within each snapshot and temporal evolution across snapshots. However, most existing methods are stateless: the…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12419" target="_blank">Intent-Driven Smart Manufacturing Integrating Knowledge Graphs and Large Language Models</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12419v1 Announce Type: new 
Abstract: The increasing complexity of smart manufacturing environments demands interfaces that can translate high-level human intents into machine-executable actions. This paper presents a unified framework that integrates instruction-tuned…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12544" target="_blank">Scaling Web Agent Training through Automatic Data Generation and Fine-grained Evaluation</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12544v1 Announce Type: new 
Abstract: We present a scalable pipeline for automatically generating high-quality training data for web agents. In particular, a major challenge in identifying high-quality training instances is trajectory evaluation - quantifying how much …</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12566" target="_blank">To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12566v1 Announce Type: new 
Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) plays a key role in stimulating the explicit reasoning capability of Large Language Models (LLMs). We can achieve expert-level performance in some specific domains via RLVR, suc…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12586" target="_blank">Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12586v1 Announce Type: new 
Abstract: While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introd…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12617" target="_blank">GeoAgent: Learning to Geolocate Everywhere with Reinforced Geographic Characteristics</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12617v1 Announce Type: new 
Abstract: This paper presents GeoAgent, a model capable of reasoning closely with humans and deriving fine-grained address conclusions. Previous RL-based methods have achieved breakthroughs in performance and interpretability but still remai…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12631" target="_blank">AI Agents for Inventory Control: Human-LLM-OR Complementarity</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12631v1 Announce Type: new 
Abstract: Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumpt…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12662" target="_blank">Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12662v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses,…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12665" target="_blank">Evaluating Robustness of Reasoning Models on Parameterized Logical Problems</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12665v1 Announce Type: new 
Abstract: Logic provides a controlled testbed for evaluating LLM-based reasoners, yet standard SAT-style benchmarks often conflate surface difficulty (length, wording, clause order) with the structural phenomena that actually determine satis…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12670" target="_blank">SkillsBench: Benchmarking How Well Agent Skills Work Across Diverse Tasks</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12670v1 Announce Type: new 
Abstract: Agent Skills are structured packages of procedural knowledge that augment LLM agents at inference time. Despite rapid adoption, there is no standard way to measure whether they actually help. We present SkillsBench, a benchmark of …</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12748" target="_blank">X-SYS: A Reference Architecture for Interactive Explanation Systems</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12748v1 Announce Type: new 
Abstract: The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system capabilit…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12852" target="_blank">WebClipper: Efficient Evolution of Web Agents with Graph-based Trajectory Pruning</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12852v1 Announce Type: new 
Abstract: Deep Research systems based on web agents have shown strong potential in solving complex information-seeking tasks, yet their search efficiency remains underexplored. We observe that many state-of-the-art open-source web agents rel…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12876" target="_blank">BrowseComp-$V^3$: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12876v1 Announce Type: new 
Abstract: Multimodal large language models (MLLMs), equipped with increasingly advanced planning and tool-use capabilities, are evolving into autonomous agents capable of performing multimodal web browsing and deep search in open-world envir…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12963" target="_blank">Information-theoretic analysis of world models in optimal reward maximizers</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12963v1 Announce Type: new 
Abstract: An important question in the field of AI is the extent to which successful behaviour requires an internal representation of the world. In this work, we quantify the amount of information an optimal policy provides about the underly…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.13093" target="_blank">Consistency of Large Reasoning Models Under Multi-Turn Attacks</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.13093v1 Announce Type: new 
Abstract: Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models …</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.13135" target="_blank">Constrained Assumption-Based Argumentation Frameworks</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.13135v1 Announce Type: new 
Abstract: Assumption-based Argumentation (ABA) is a well-established form of structured argumentation. ABA frameworks with an underlying atomic language are widely studied, but their applicability is limited by a representational restriction…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.13166" target="_blank">Optimal Take-off under Fuzzy Clearances</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.13166v1 Announce Type: new 
Abstract: This paper presents a hybrid obstacle avoidance architecture that integrates Optimal Control under clearance with a Fuzzy Rule Based System (FRBS) to enable adaptive constraint handling for unmanned aircraft. Motivated by the limit…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2511.13494" target="_blank">Language-Guided Invariance Probing of Vision-Language Models</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2511.13494v1 Announce Type: cross 
Abstract: Recent vision-language models (VLMs) such as CLIP, OpenCLIP, EVA02-CLIP and SigLIP achieve strong zero-shot performance, but it is unclear how reliably they respond to controlled linguistic perturbations. We introduce Language-Gu…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.11247" target="_blank">Peak + Accumulation: A Proxy-Level Scoring Formula for Multi-Turn LLM Attack Detection</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.11247v1 Announce Type: cross 
Abstract: Multi-turn prompt injection attacks distribute malicious intent across multiple conversation turns, exploiting the assumption that each turn is evaluated independently. While single-turn detection has been extensively studied, no…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12284" target="_blank">A Lightweight LLM Framework for Disaster Humanitarian Information Classification</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12284v1 Announce Type: cross 
Abstract: Timely classification of humanitarian information from social media is critical for effective disaster response. However, deploying large language models (LLMs) for this task faces challenges in resource-constrained emergency set…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12285" target="_blank">From Biased Chatbots to Biased Agents: Examining Role Assignment Effects on LLM Agent Robustness</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12285v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are increasingly deployed as autonomous agents capable of actions with real-world impacts beyond text generation. While persona-induced biases in text generation are well documented, their effects on …</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12287" target="_blank">Retrieval-Augmented Self-Taught Reasoning Model with Adaptive Chain-of-Thought for ASR Named Entity Correction</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12287v1 Announce Type: cross 
Abstract: End-to-end automatic speech recognition (ASR) systems frequently misrecognize domain-specific phrases like named entities, which can cause catastrophic failures in downstream tasks. A new family of named entity correction methods…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12288" target="_blank">Energy-Aware Reinforcement Learning for Robotic Manipulation of Articulated Components in Infrastructure Operation and Maintenance</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12288v1 Announce Type: cross 
Abstract: With the growth of intelligent civil infrastructure and smart cities, operation and maintenance (O&M) increasingly requires safe, efficient, and energy-conscious robotic manipulation of articulated components, including access do…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12296" target="_blank">Adaptive traffic signal control optimization using a novel road partition and multi-channel state representation method</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12296v1 Announce Type: cross 
Abstract: This study proposes a novel adaptive traffic signal control method leveraging a Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) to optimize signal timing by integrating variable cell length and multi-channel state rep…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12304" target="_blank">OmniCustom: Sync Audio-Video Customization Via Joint Audio-Video Generation Model</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12304v1 Announce Type: cross 
Abstract: Existing mainstream video customization methods focus on generating identity-consistent videos based on given reference images and textual prompts. Benefiting from the rapid advancement of joint audio-video generation, this paper…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12305" target="_blank">OptiML: An End-to-End Framework for Program Synthesis and CUDA Kernel Optimization</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12305v1 Announce Type: cross 
Abstract: Generating high-performance CUDA kernels remains challenging due to the need to navigate a combinatorial space of low-level transformations under noisy and expensive hardware feedback. Although large language models can synthesiz…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12306" target="_blank">Quantum walk inspired JPEG compression of images</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12306v1 Announce Type: cross 
Abstract: This work proposes a quantum inspired adaptive quantization framework that enhances the classical JPEG compression by introducing a learned, optimized Qtable derived using a Quantum Walk Inspired Optimization (QWIO) search strate…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12311" target="_blank">Perceptual Self-Reflection in Agentic Physics Simulation Code Generation</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12311v1 Announce Type: cross 
Abstract: We present a multi-agent framework for generating physics simulation code from natural language descriptions, featuring a novel perceptual self-reflection mechanism for validation. The system employs four specialized agents: a na…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12313" target="_blank">Visible and Hyperspectral Imaging for Quality Assessment of Milk: Property Characterisation and Identification</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12313v1 Announce Type: cross 
Abstract: Rapid and non-destructive assessment of milk quality is crucial to ensuring both nutritional value and food safety. In this study, we investigated the potential of visible and hyperspectral imaging as cost-effective and quick-res…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12315" target="_blank">AgenticShop: Benchmarking Agentic Product Curation for Personalized Web Shopping</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12315v1 Announce Type: cross 
Abstract: The proliferation of e-commerce has made web shopping platforms key gateways for customers navigating the vast digital marketplace. Yet this rapid expansion has led to a noisy and fragmented information environment, increasing co…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12317" target="_blank">Free Lunch in Medical Image Foundation Model Pre-training via Randomized Synthesis and Disentanglement</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12317v1 Announce Type: cross 
Abstract: Medical image foundation models (MIFMs) have demonstrated remarkable potential for a wide range of clinical tasks, yet their development is constrained by the scarcity, heterogeneity, and high cost of large-scale annotated datase…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12322" target="_blank">ForeAct: Steering Your VLA with Efficient Visual Foresight Planning</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12322v1 Announce Type: cross 
Abstract: Vision-Language-Action (VLA) models convert high-level language instructions into concrete, executable actions, a task that is especially challenging in open-world environments. We present Visual Foresight Planning (ForeAct), a g…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12342" target="_blank">Intrinsic Credit Assignment for Long Horizon Interaction</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12342v1 Announce Type: cross 
Abstract: How can we train agents to navigate uncertainty over long horizons? In this work, we propose {\Delta}Belief-RL, which leverages a language model's own intrinsic beliefs to reward intermediate progress. Our method utilizes the cha…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12373" target="_blank">Policy4OOD: A Knowledge-Guided World Model for Policy Intervention Simulation against the Opioid Overdose Crisis</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12373v1 Announce Type: cross 
Abstract: The opioid epidemic remains one of the most severe public health crises in the United States, yet evaluating policy interventions before implementation is difficult: multiple policies interact within a dynamic system where target…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12375" target="_blank">Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12375v1 Announce Type: cross 
Abstract: Optimistic value estimates provide one mechanism for directed exploration in reinforcement learning (RL). The agent acts greedily with respect to an estimate of the value plus what can be seen as a value bonus. The value bonus ca…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12380" target="_blank">TFT-ACB-XML: Decision-Level Integration of Customized Temporal Fusion Transformer and Attention-BiLSTM with XGBoost Meta-Learner for BTC Price Forecasting</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12380v1 Announce Type: cross 
Abstract: Accurate forecasting of Bitcoin (BTC) has always been a challenge because decentralized markets are non-linear, highly volatile, and have temporal irregularities. Existing deep learning models often struggle with interpretability…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12384" target="_blank">Why Deep Jacobian Spectra Separate: Depth-Induced Scaling and Singular-Vector Alignment</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12384v1 Announce Type: cross 
Abstract: Understanding why gradient-based training in deep networks exhibits strong implicit bias remains challenging, in part because tractable singular-value dynamics are typically available only for balanced deep linear models. We prop…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12390" target="_blank">Rational Neural Networks have Expressivity Advantages</a></h3>
          <div class="meta">arXiv cs.AI • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12390v1 Announce Type: cross 
Abstract: We study neural networks with trainable low-degree rational activation functions and show that they are more expressive and parameter-efficient than modern piecewise-linear and smooth activations such as ELU, LeakyReLU, LogSigmoi…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12302" target="_blank">Grandes Modelos de Linguagem Multimodais (MLLMs): Da Teoria \`a Pr\'atica</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12302v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) combine the natural language understanding and generation capabilities of LLMs with perception skills in modalities such as image and audio, representing a key advancement in contemporary AI…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12414" target="_blank">propella-1: Multi-Property Document Annotation for LLM Data Curation at Scale</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12414v1 Announce Type: new 
Abstract: Since FineWeb-Edu, data curation for LLM pretraining has predominantly relied on single scalar quality scores produced by small classifiers. A single score conflates multiple quality dimensions, prevents flexible filtering, and off…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12424" target="_blank">RankLLM: Weighted Ranking of LLMs by Quantifying Question Difficulty</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12424v1 Announce Type: new 
Abstract: Benchmarks establish a standardized evaluation framework to systematically assess the performance of large language models (LLMs), facilitating objective comparisons and driving advancements in the field. However, existing benchmar…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12445" target="_blank">RBCorr: Response Bias Correction in Language Models</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12445v1 Announce Type: new 
Abstract: Language models (LMs) are known to be prone to response biases, which present as option preference biases in fixed-response questions. It is therefore imperative to develop low-cost and effective response bias correction methods to…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12575" target="_blank">Discovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12575v1 Announce Type: new 
Abstract: Psychological scale refinement traditionally relies on response-based methods such as factor analysis, item response theory, and network psychometrics to optimize item composition. Although rigorous, these approaches require large …</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12635" target="_blank">Unleashing Low-Bit Inference on Ascend NPUs: A Comprehensive Evaluation of HiFloat Formats</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12635v1 Announce Type: new 
Abstract: As LLMs scale, low-bit floating-point formats like MXFP and NVFP4 offer new opportunities for precision and efficiency. In this work, we evaluate HiFloat (HiF8 and HiF4), a family of formats tailored for Ascend NPUs. Through rigoro…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12639" target="_blank">CLASE: A Hybrid Method for Chinese Legalese Stylistic Evaluation</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12639v1 Announce Type: new 
Abstract: Legal text generated by large language models (LLMs) can usually achieve reasonable factual accuracy, but it frequently fails to adhere to the specialised stylistic norms and linguistic conventions of legal writing. In order to imp…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12642" target="_blank">Beyond Normalization: Rethinking the Partition Function as a Difficulty Scheduler for RLVR</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12642v1 Announce Type: new 
Abstract: Reward-maximizing RL methods enhance the reasoning performance of LLMs, but often reduce the diversity among outputs. Recent works address this issue by adopting GFlowNets, training LLMs to match a target distribution while jointly…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12660" target="_blank">Learning Ordinal Probabilistic Reward from Preferences</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12660v1 Announce Type: new 
Abstract: Reward models are crucial for aligning large language models (LLMs) with human values and intentions. Existing approaches follow either Generative (GRMs) or Discriminative (DRMs) paradigms, yet both suffer from limitations: GRMs ty…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12674" target="_blank">$\mathcal{X}$-KD: General Experiential Knowledge Distillation for Large Language Models</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12674v1 Announce Type: new 
Abstract: Knowledge Distillation (KD) for Large Language Models (LLMs) has become increasingly important as models grow in size and complexity. While existing distillation approaches focus on imitating teacher behavior, they often overlook t…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12705" target="_blank">MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12705v1 Announce Type: new 
Abstract: We present MedXIAOHE, a medical vision-language foundation model designed to advance general-purpose medical understanding and reasoning in real-world clinical applications. MedXIAOHE achieves state-of-the-art performance across di…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12709" target="_blank">ReFilter: Improving Robustness of Retrieval-Augmented Generation via Gated Filter</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12709v1 Announce Type: new 
Abstract: Retrieval-augmented generation (RAG) has become a dominant paradigm for grounding large language models (LLMs) with external evidence in knowledge-intensive question answering. A core design choice is how to fuse retrieved samples …</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12746" target="_blank">Lamer-SSL: Layer-aware Mixture of LoRA Experts for Continual Multilingual Expansion of Self-supervised Models without Forgetting</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12746v1 Announce Type: new 
Abstract: Despite their impressive performance, self-supervised speech models often struggle to generalize to new languages and tend to forget previously acquired knowledge during continual training. To address this, we propose Lamer-SSL, a …</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12759" target="_blank">Towards a Diagnostic and Predictive Evaluation Methodology for Sequence Labeling Tasks</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12759v1 Announce Type: new 
Abstract: Standard evaluation in NLP typically indicates that system A is better on average than system B, but it provides little info on how to improve performance and, what is worse, it should not come as a surprise if B ends up being bett…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12778" target="_blank">Aspect-Based Sentiment Analysis for Future Tourism Experiences: A BERT-MoE Framework for Persian User Reviews</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12778v1 Announce Type: new 
Abstract: This study advances aspect-based sentiment analysis (ABSA) for Persian-language user reviews in the tourism domain, addressing challenges of low-resource languages. We propose a hybrid BERT-based model with Top-K routing and auxili…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12806" target="_blank">RAT-Bench: A Comprehensive Benchmark for Text Anonymization</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12806v1 Announce Type: new 
Abstract: Data containing personal information is increasingly used to train, fine-tune, or query Large Language Models (LLMs). Text is typically scrubbed of identifying information prior to use, often with tools such as Microsoft's Presidio…</p>
        </article>
        

        <article class="card">
          
          <h3><a href="https://arxiv.org/abs/2602.12811" target="_blank">Left-right asymmetry in predicting brain activity from LLMs' representations emerges with their formal linguistic competence</a></h3>
          <div class="meta">arXiv cs.CL • arxiv.org • 16.02.2026 05:00 UTC</div>
          <p>arXiv:2602.12811v1 Announce Type: new 
Abstract: When humans and large language models (LLMs) process the same text, activations in the LLMs correlate with brain activity measured, e.g., with functional magnetic resonance imaging (fMRI). Moreover, it has been shown that, as the t…</p>
        </article>
        
</section>
</main>
<footer class="footer">
  <p>&copy; 2026 KI‑Ticker</p>
</footer>
</body>
</html>
